# Prétraitements des données

Pour faire de la modélisation prédictive, il est généralement inévitable de faire des prétraitements aux données pour exploiter autant que possible les différents algorithmes d'apprentissage. Ces prétraitements permettront de réaliser 2 choses:

1. Transformer les données dans un format compatible pour l'algorithme.
2. Transformer les données de manière à faciliter l'apprentissage.

À ce stade-ci, nous n'avons pas seulement des données sous la main, mais également une certaine connaissance de ces données acquise grâce à l'analyse de données \@ref(exploration). Dans cette section, nous serons donc en mesure de produire des données propices à l'apprentissage qui sera faite dans la section \@ref(metho). Pour se faire, nous allons couvrir la théorie derrière le nettoyage, la réduction et la transformation de données. Ensuite, nous allons voir comment intégrer cette théorie dans le processus de modélisation. Finalement, nous allons présenter des packages en R qui permettent de faciliter ce pré-traitement de données.

## Théorie

Cette section a comme objectif de couvrir les concepts théoriques à la base du prétraitement de données. L'objectif est de présenter pourquoi il est primordial de considérer ces étapes avant de lancer des algorithmes d'apprentissage.

### Nettoyage de données

La première étape du prétraitement de données consite à nettoyer les données. Après cette étape, l'algorithme devrait au minimum être en mesure de fonctionner. Le nettoyage de données comprends plusieurs traitements propres à chaque jeu de données, voici les ceux que nous avons identifiés et qui sont assez générales : 

1. Imputation de données manquantes
2. Traitement des données aberrantes
3. Encodage des données catégoriques

#### Imputation de données manquantes

La majorité des jeux de données réels sont témoins de données manquantes. Certains algorithmes ne sont pas en mesure de gérer les données manquantes par eux-mêmes. Cela nous oblige donc à traiter celles-ci et imputer le jeu de données. Les causes d'absence de données peuvent être relativement variées: bris de système, abstention, perte de données, etc. Il est généralement difficile de connaître la raison exacte, ce qui rend le traitement de données manquantes une étape importante. Avant même de trouver une méthode pour imputer ces données manquantes, il faut d'abord évaluer la quantité de données manquantes (% par variable) et tenter de comprendre le mécanisme expliquant la non-réponse d'une donnée. Il existe essentiellement 3 types de mécanismes de non-réponse:

1. Données manquantes complètement au hasard (MCAR)
2. Données manquantes au hasard (MAR)
3. Données manquantes pas au hasard (NMAR)

Dans le premier cas (MCAR), l'absence de donnée ne dépend pas de la vraie donnée. Par exemple, un système est défaillant dans la collecte de données et arrête de fonctionner en moyenne 5% du temps, et ce, de manière complètement aléatoire.

Dans le deuxième cas (MAR), l'absence de donnée dépend uniquement de la valeur des variables qui ont été observées. Par exemple, des données ont été récoltées à partir de 2 systèmes différents et il est toujours connu de quel système les données proviennent. Pour un des deux systèmes, les données ont une plus grande probabilité d'être manquante.

Dans le troisième cas (NMAR), l'absence de donnée dépend également des données manquantes. La probabilité de non-réponse peut dépendre de la variable elle-même ou d'une autre variable. Par exemple, c'est le cas si les personnes ayant un salaire faible ont une probabilité plus faible de répondre à la question d'un sondage en lien avec le salaire gagné.

[citer le cours d'anne-sophie]

Il existe différentes manières d'émettre une hypothèse quant au mécanisme de non-réponse. Certains tests [^tests] statistiques existent pour identifier un cas de MCAR. Cependant, il est difficile de différencier statistiquement MAR et NMAR. Pour se faire, on peut entres autres analyser le comportement des autres variables en fonction de l'absence ou la présence d'une donnée. Une connaissance du domaine d'affaire peut également être utile pour évaluer le mécanisme de non-réponse. Par la suite, il est possible de faire l'imputation selon différentes méthodes:

[^tests]: Voir le test de Welch et le test de Little. Les deux tests ne peuvent garantir l'hypothèse de MCAR. 

*Analyse des cas complets* <br>
Conserver uniquement les observations pour lesquelles toutes les variables sont présentes. Cette méthode est très simple, mais nécessite MCAR, sinon peut introduire un biais notable dans les estimateurs.
<br>

*Imputation par une mesure de centralité* <br>
Utiliser la moyenne ou la médianne pour remplacer les données manquantes. Cette méthode est relativement simple, mais peu recommandée pour des variables ayant un pourcentage élevé de données manquantes (même pour MCAR). Cela diminue la variabilité et la corrélation entre les variables. 

*Imputation par régression* <br>
*Imputation par régression stochastique* <br>

En bref, il est important d'avoir une bonne compréhension des données manquantes dans le jeu de donnée. Cela nous permet de prendre des décisions éclairées sur les techniques utilisées pour imputer ces valeurs manquantes. 

#### Traitement des données aberrantes
#### Encodage des données catégoriques

### Réduction de données

Plus parler du fléeau de la dimensionnalité. Proposer des méthodes comme PCA pour réduire la dimensionnalité.

### Transformation de données

- Smoothing, binnings, features enginnering

## Intégration

- Outputer un json (ou des objets .rds) permettant de faire l'imputation en prod
- Méthode pour faire le one-hot encoding
- Avoir une fonction par feature et parler du naming pour les variables raw versus features

## Packages suggérés

- `Hmisc` 
- `missForest`
- `MICE` (pas mon pref, difficile à reconduire en prod)

Je dois faire des tests et investiguer plus les deux premiers. 

## Exemple
