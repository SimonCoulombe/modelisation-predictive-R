# Méthodologie de construction de modèles



(...) Ce qu'on a fait à date:

- Retour sur 1-2-3-4
- Donc: les jeux de données sont bien structurés (propres)




(...) Ce qu'on veut faire maintenant:

Supposons pour l'instant que notre variable réponse $Y$ est quantitative. En introduction du monographe, nous avons fait l'hypothèse qu'une fonction $f$ connecte nos variables explicatives $X$ à $Y$ de telle sorte que
$$
  \mathbf{y} \approx f(\mathbf{X}).
$$
L'objectif principal, dans ce chapitre, est d'apprendre (ou plutôt d'approximer) la fonction $f$ à l'aide de la théorie de l'apprentissage statistique. Plusieurs éléments sont tirés des livres *An Introduction to Statistical Learning: with Application in R* de Gareth James, Daniela Witten, Trevor Hastie et Robert Tibshirani; *The Elements of Statistical Learning* de Trevor Hastie, Robert Tibshirani et Jerome H. Friedman; et finalement *R for Data Science* de Hadley Wickham et Garrett Grolemund. Le terme *apprentissage statstique* a été grandement popularisé par les auteurs des deux premières références, qui donne la définition (traduction libre)

>> L'apprentissage statistique fait référence à un ensemble d'outils pour modéliser et comprendre des jeux de données complexes. C'est une sous-discipline récente de la statistique qui se développe en parallèle avec les avancées en informatique et, plus particulièrement, en apprentissage automatique.


Nous supposons que le lecteur possède des connaissances de base en statistique (distribution, espérance, variance, etc).


(...) Librairies et références:

- modélisation (général): caret?
- modèles: glmnet, xgBoost
*Selon le modèle choisi.


Dans ce chapitre, nous abordons la gestion des données; l'identification de modèles adéquats; l'estimation de modèles (fonction de perte, compromis biais-variance); la sélection d'un modèle (AIC,BIC,validation croisée); et l'évaluation de ce modèle (erreur de généralisation). 


## Théorie

### Gestion des données

Pour plusieurs raisons, il est conseillé de commencer par séparer aléatoirement son jeu de données en trois partie distinctes : les jeux de données d'entraînement, de validation et de test.
Chacune des trois parties est associées à une étape de la construction du modèle. Les données d'entrainement serviront à estimer nos modèles; les données de validation à sélectionner un modèle; les données de test à évaluer le modèle final.
Lorsque le nombre d'observation le permet, la règle du pouce généralement employée est d'utiliser la moitié(e?) des observations pour l'entrainement et le quart pour chacune des deux autres étapes.

IMAGE

Il est important de garder en tête que ce n'est qu'une *règle du pouce*.
Si le jeu de données contient peu de signal (d'information) pour prédire $\mathbf{y}$, il se peut qu'en laissant de côté certaines observations, l'estimation des modèles soit trop déficiente pour être utile.
Les étapes des Chapitre **REF** permettent généralement aux scientifique des données de faire une idée de la situation.

On associe aux jeux de données d'entraînement l'*erreur d'entrainement*, qui est l'erreur qu'on minimise lors de l'estimation du modèle.
En contrepartie, les jeux de données de validation et de test servent tous deux à estimer l'*erreur de généralisation*, c'est-à-dire l'erreur faite sur de **nouvelles** données.
Cela explique d'ailleurs la confusion entourant ces derniers et leur utilité.
Les données de validation servent à choisir un modèle parmi tous ceux estimés.
À titre d'exemples concrets, ceci permet de choisir le nombre d'interactions croisées dans un modèle linéaire généralisé ou le nombre de couches cachées dans un réseau de neurones.
Malgré que ce ne soit pas particulièrement conseillé, il peut arriver que l'on veuille re-mélangé les jeux d'entrainement et de validation lors du processus.
Il est absolument impératif toutefois de garder les données de test dans un coffre-fort bien cellé.
Sinon, notre estimation finale de l'*erreur de généralisation* pourrait être induement optimiste. Il faut garder en tête que l'objectif est de prédire de **nouvelles** valeurs $\mathbf{y}$ à l'aide de **nouvelles** valeurs $\mathbf{X}$; l'erreur de généralisation est donc au coeur de nos préoccupations.

Lorsque trop peu de données sont disponible, l'étape de test doit souvent être abandonnée et des techniques plus sophistiquées peuvent nous permettre d'estimer l'erreur de généralisation à partir des données d'entrainement.
On verra toutefois que ces méthodes estiment l'*erreur de généralisation* moyenne conditionelle aux données $X$.
Ces dernières sont d'ailleurs expliquées en fin de chapitre.
D'ici là, nous utilisons $\mathbf{X}$ en tant que données d'entrainement.


### Identification d'un modèle

Commençons d'abord en reformulant REF en tant qu'égalité stricte.
Pour ce faire, on introduit une quantité aléatoire $\varepsilon$ qui représente la variabilité non captée par notre modèle.
Cela donne ainsi l'équation
$$
  y = f(\mathbf{x}) + \varepsilon.
$$
Quand $Y$ est une variable continue, il est naturel de faire les deux hypothèses suivantes à propos de $\varepsilon$.
Tout d'abord, on suppose que sa valeur moyenne est nulle, c'est-à-dire $\mathbf{E}(\varepsilon) = 0$.
Ceci nous permet entre autre d'oublier $\varepsilon$ lorsque vient le temps de faire une prédiction.
Étant donné $\mathbf{x}$, on s'attend à ce qu'en moyenne $y$ soit égale à $f(\mathbf{x})$, *i.e.* $\mathbf{E}(Y) = f(X)$.
On stipule aussi souvent, à des fins de simplification, que $\varepsilon$ et $\mathbf{x}$ sont indépendants.

Notons qu'en introduisant $\varepsilon$, on admet l'existence d'une erreur *irréductible* : même si nous réussissions à estimer $f$ parfaitement, il faudrait s'attendre à ce que nos prédictions ne soient pas nécéssairement parfaite.
Ceci s'explique par la présence de facteurs influençant $Y$ auxquels nous n'avons pas accès (qui ne sont pas mesurés) ou qui ne sont simplement pas mesurables; mais aussi par un choix de modèle $f$ qui ne permet pas de capturer l'essentiel de la relation entre $X$ et $Y$.
Ainsi, pour minimiser l'erreur dite *réductible* autant que possible, il est nécessaire d'accéder à un maximum d'information (pertinente! et si possible non-redondante) et de choisir une famille de modèles appropriée pour le problème qui nous intéresse.
On divise généralement les problèmes en deux grandes catégories : la régression et la classification.
La régression sous-entend une variable réponse continue, *e.g.* la grandeur d'une individue ; la classification sous-entend une variable réponse catégorique (une classe), *e.g.* chat ou chien.
Plusieurs exemples de ces deux types de modèles sont présentés dans la dernière section du chapitre.

Un modèle est en fait un ensemble de contraintes qu'on impose à la fonction $f$ de REF.
L'introduction de contraintes limite le type de relation entre $Y$ et $\mathbf{X}$ qu'il sera possible d'apprendre ; paradoxalement, c'est aussi ce qui permet l'apprentissage.
Par exemple, la (bien connue!) régression linéaire sous-entend une relation linéaire entre la variable réponse (continue) et les facteur explicatifs :
$$
  Y = f(\mathbf{X}) + \varepsilon = \beta_0 + \beta_1 X_1 + \dots + \beta_1 X_d + \varepsilon
$$
La plupart du temps, les modèles plus contraignants sont favorisés lorsque peu d'observations sont disponibles.
Lorsque justifiées, de telles contraintes permettent de prendre avantage d'une structure dans les données qui est connue (ou supposée) *à priori*.
Certains modèles comme les réseaux de neurones profonds sont reconnus pour être efficaces dans des cas ou la relation entre les variables peut être très complexe, mais requierent généralement une quantité astromnomique de données.
Certains modèles plus simples, comme la régression linéaire justement, sont parfois favorisés aussi pour leur meilleure interprétabilité.
Dans ce document, nous nous intéressons plusau pouvoir prédictif qu'à l'interprétabilité.

Pour plus de détails sur la classification, voir le premier exemple en fin de chapitre qui concerne la méthode des $K$ plus proches voisins.
Nous supposons une variable continue pour le reste de la partie théorique.

Revenons à l'exemple des usagers BIXI. 
Une particularité de notre objectif est de prédire une proportion, qui doit nécessairement être entre 0 et 1.
La régression linéaire en REF n'assure pas que cette contrainte soit satisfaite.
Pour l'intégrer au modèle, on peut modifier le côté gauche de l'équation de telle sorte qu'il puisse prendre toutes les valeurs réelles, en s'assurant néanmoins que notre variable $y$ elle reste entre 0 et 1.
On utilise ici la fonction *logit*, qui donne
$$
  \mathrm{ln}\left( \frac{y}{1-y} \right) = \beta_0 + \beta_1 x_1 + \dots + \beta_d x_d + \varepsilon.
$$
Cette modification porte le nom de régression logistique et est un cas particulier de modèle linéaire généralisé. Le cas général est présenté en exemple à la fin du chapitre.
PLUS DE VARIABLES -- arrondissement et heure...


### Estimation d'un modèle

Estimer un modèle consiste à déterminer les valeurs de ses paramètres.
Les paramètres sont choisis de telle sorte que le modèle soit le plus précis possible dans ses prédictions (sur les données d'entraînement).
On cherche à minimiser l'*erreur de prédiction* du modèle, ce qui sous-entend donc qu'on puisse quantifier cette erreur.
Pour ce faire, on utilise une fonction de perte $L(y,\hat{y}) = L(y,f(x))$, qui détermine la pénalité associée à une prédiction.
Dans certains cas comme la détection de fraude, où une transaction identifiée comme frauduleuse sera vérifiée par une agente, il peut être souhaitable de minimiser le nombre de faux négatifs (les transactions frauduleuse qui nous glissent entre les doigts), quitte à introduire plus de faux positifs (des transactions identifiées frauduleuses qui ne le sont pas réellement).
Le choix de $L$ doit donc s'aligner avec nos attentes par rapport au modèle.
Concentrons-nous sur des cas plus classiques.
La fonction de perte la plus populaire est sans contredit l'erreur quadratique, aussi appelée la somme des carrés, $L(y,\hat{y}) = (\hat{y} - y)^2$.
Puisque nous avons à notre disposition plusieurs observations (supposées indépendantes), il s'agit de minimiser l'*erreur prédictive moyenne*, ou de façon équivalente la somme des erreur de prédiction.
Pour la régression linéaire (qui détermine $f(\mathbf{x})$) et l'erreur quadratique (qui détermine $L$), on obtient
$$
  \sum_{i=1}^n L(y_i,\hat{y}_i) = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n \Big(y_i - (\beta_0 + \beta_1 x_{i1} + \dots + \beta_1 x_{id})\Big)^2.
$$
En notation matricielle, c'est-à-dire lorsqu'on considère $\mathbf{y} \in \mathbb{R}^n$ et $\mathbf{X} \in \mathbb{R}^{n \times d}$, cela donne (en supposant ici $\beta_0 = 0$)
$$
  \mathrm{argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n L(y_i,\hat{y}_i) = \mathrm{argmin}_{\mathbf{\beta}} \ (\mathbf{y} - \mathbf{X}^\top \boldsymbol{\beta})^{\top}(\mathbf{y} - \mathbf{X}^\top \boldsymbol{\beta}) = (\mathbf{X} \mathbf{X}^\top)^{-1} \mathbf{X} \mathbf{y},
$$
un estimateur bien connu.



- Un mot très rapide sur la régularisation (l2 (ridge), l1 (lasso), l1+l2 (elastic net))



### Sélection d'un modèle
- *erreur de généralization*
- estimation via la division du jeu de données (train/test/val) -- note sur caret qui permet la séparation
- estimation via CV (Jackknife et son évolution)
- estimation via bootstrap


## Intégration


## Exemples

**Exemples**

À des fins explicatives, nous focaliserons ici sur la méthode des $K$ plus proche voisins ($K$-ppv, notre traduction de $K$-nn, *K nearest neighbors*).
Elle peut servir par exemple pour prédire le type $y^*$ (membre vs non-memmbre) du prochain utilisateur BIXI, étant données l'heure $x^*$ de sa location.
Une façon naturelle de procéder consiste à trouver les $K$ usagers de notre jeux de données ayant utilisé le service aux heures les plus similaires et d'assigner à $y^*$ la catégorie la plus fréquente parmis les $K$ usagers retenus $y_{i_1},\dots,y_{i_K}$.
Dans cet exemple, la fonction $f$ implicite est
$$
  f(x^*) = \mathrm{mode}(x_{i_1},\dots,x_{i_K}), \qquad (x_{i_1},\dots,x_{i_K}) = \mathrm{argmin}_{(j_1,\dots,j_K)} \sum_{k=1}^K |x_{j_k} - x^*|.
$$
Malgré sa forme fonctionnelle quelque peu épeurante, la méthode est terriblement simple.
L'expression de droite consiste à trouver les $K$ usagers les plus similaires : on minimise la différence entre l'heure qui nous intéresse $x^*$ et celles des usagers choisis.
L'expression de gauche calcule la classe la plus fréquente.

Cette méthode peut aussi être utilisée pour prédire des variables continues comme celle qui nous intéresse, la proportion de membres parmi les usagers selon l'heure et l'arondissement. En nous restreignant encore à l'heure d'utilisation seulement, cela correspondrait à
$$
  f(x^*) = \frac{1}{K} \sum_{k=1}^K x_{i_k}, \qquad (x_{i_1},\dots,x_{i_K}) = \mathrm{argmin}_{(j_1,\dots,j_K)} \sum_{k=1}^K |x_{j_k} - x^*|.
$$


Un exemple pour chacune des trois méthodes.

  - régression linéaire (mention : bien comprendre les modèles linéaires est essentiel pour comprendre les modèles non-linéaire)
  - modèles lineaires généralisé (reg. logistique)
  - modèles additifs
  - arbres de décisions (boosted trees)
  - SVM (note : plus populaire en info)

**NOTE :** a-t-il été mention de...

- $g(Y) = f(X) + \epsilon$ -- modèle additif versus modèle multiplicatif?
