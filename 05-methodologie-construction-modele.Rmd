# Méthodologie de construction de modèles


## Mise en contexte


(...) Ce qu'on a fait à date:

- Retour sur 1-2-3-4
- Donc: les jeux de données sont bien structurés (propres)




(...) Ce qu'on veut faire maintenant:

Supposons pour l'instant que notre variable réponse $Y$ est quantitative. En introduction du monographe, nous avons fait l'hypothèse de l'existence d'une relation $f$ connectant nos variables explicative $X$ à cette dernière de telle sorte que
$$
  Y \approx f(X).
$$
L'objectif principal, dans ce chapitre, est d'apprendre (ou plutôt d'approximer) la fonction $f$ à l'aide de la théorie de l'apprentissage statistique. C'EST QUOI CA? **CITE ESL et ISL** Nous supposons que le lecteur possède des connaissances de base en statistique (*e.g.* une vague idée du sens des termes distribution, espérance, variance, etc).


(...) Librairies:

- modélisation (général): caret?
- modèles: glmnet, xgBoost

*Selon le modèle choisi.


(...) Dans ce chapitre

- Définition d'un modèle
- Estimation de ses paramètres (concepts importants: fonction de perte, compromis biais-variance)
- Évaluation de notre ou nos modèles (concept important: erreur de généralisation)
- Avant tout, un mot sur cette dernière. Gestion des données: train/test/validation. Souvent confus.




## Identification d'un modèle

Commençons d'abord en reformulant REF en tant qu'égalité stricte. Pour ce faire, on introduit une quantité aléatoire $\varepsilon$ qui représente la variabilité non captée par notre modèle. Cela donne ainsi l'équation
$$
  Y = f(X) + \varepsilon.
$$
Dans la grande majorité des cas, il est naturel de faire les deux hypothèses suivantes à propos de $\varepsilon$.
Tout d'abord, on suppose que sa valeur moyenne est nulle, c'est-à-dire $\mathbf{E}(\varepsilon) = 0$.
Ceci nous permet entre autre d'oublier $\varepsilon$ lorsque vient le temps de faire une prédiction.
Étant donné $X$, on s'attend à ce qu'en moyenne $Y$ soit égale à $f(X)$, *i.e.* $\mathbf{E}(Y) = f(X)$.
On stipule aussi souvent, à des fins de simplification, que $\varepsilon$ et $X$ sont indépendants.

Notons qu'en introduisant $\varepsilon$, on admet l'existence d'une erreur *irréductible* : même si nous réussissions à estimer $f$ parfaitement, il faudrait s'attendre à ce que nos prédictions ne soient pas nécéssairement parfaite.
Ceci s'explique par la présence de facteurs influençant $Y$ auxquels nous n'avons pas accès (qui ne sont pas mesurés) ou qui ne sont simplement pas mesurables; mais aussi par un choix de modèle $f$ qui ne permet pas de capturer l'essentiel de la relation entre $X$ et $Y$.
Ainsi, pour minimiser l'erreur dite *réductible* autant que possible, il est nécessaire d'accéder à un maximum d'information (pertinente! et si possible non-redondante) et de choisir une famille de modèles appropriée pour le problème qui nous intéresse.

On divise généralement les tâches en deux grandes catégories : la régression et la classification. **EXPLICATIONS**

**Exemples**

(littéralement sous forme d'exemple avec des dataset bébé)

  - régression linéaire (mention : bien comprendre les modèles linéaires est essentiel pour comprendre les modèles non-linéaire)
  - modèles lineaires généralisé (reg. logistique)
  - modèles additifs
  - arbres de décisions (boosted trees)
  - SVM (note : plus populaire en info)

**NOTE :** a-t-il été mention de...

- $g(Y) = f(X) + \epsilon$ -- modèle additif versus modèle multiplicatif?
- interprétabilité vs performance (souvent lié à inférence vs prédiction)


## Estimation d'un modèle

- Un mot rapide sur le split (train/test/val) et les différentes erreurs (de prédiction et de généralisation)
- fonction de perte (loss function/objective function)
- ajustement du modèle: minimisation de l'erreur de prédiction moyenne.
- explication avec un modèle simple : régression linéaire (ajuster les betas)
- Un mot très rapide sur la régularisation (l2 (ridge), l1 (lasso), l1+l2 (elastic net))



**Exemples (suite)**

  - modèles lineaires généralisé (glmnet)
  - modèles additifs (xgBoost)
  - arbres de décisions (boosted trees - xgBoost)
  - SVM (?)



## Sélection d'un modèle
- *erreur de généralization*
- estimation via la division du jeu de données (train/test/val) -- note sur caret qui permet la séparation
- estimation via CV (Jackknife et son évolution)
- estimation via bootstrap


**Exemples**

Un exemple pour chacune des trois méthodes.
